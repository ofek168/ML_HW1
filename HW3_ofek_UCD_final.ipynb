{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "In this assignment, we will be building a Na√Øve Bayes classifier and a SVM model for the productivity satisfaction of [the given dataset](https://archive.ics.uci.edu/ml/datasets/Productivity+Prediction+of+Garment+Employees), the productivity of garment employees.\n",
    "\n",
    "## Background\n",
    "The Garment Industry is one of the key examples of the industrial globalization of this modern era. It is a highly labour-intensive industry with lots of manual processes. Satisfying the huge global demand for garment products is mostly dependent on the production and delivery performance of the employees in the garment manufacturing companies. So, it is highly desirable among the decision makers in the garments industry to track, analyse and predict the productivity performance of the working teams in their factories. \n",
    "\n",
    "## Dataset Attribute Information\n",
    "\n",
    "1. **date**: Date in MM-DD-YYYY\n",
    "2. **day**: Day of the Week\n",
    "3. **quarter** : A portion of the month. A month was divided into four quarters\n",
    "4. **department** : Associated department with the instance\n",
    "5. **team_no** : Associated team number with the instance\n",
    "6. **no_of_workers** : Number of workers in each team\n",
    "7. **no_of_style_change** : Number of changes in the style of a particular product\n",
    "8. **targeted_productivity** : Targeted productivity set by the Authority for each team for each day.\n",
    "9. **smv** : Standard Minute Value, it is the allocated time for a task\n",
    "10. **wip** : Work in progress. Includes the number of unfinished items for products\n",
    "11. **over_time** : Represents the amount of overtime by each team in minutes\n",
    "12. **incentive** : Represents the amount of financial incentive (in BDT) that enables or motivates a particular course of action.\n",
    "13. **idle_time** : The amount of time when the production was interrupted due to several reasons\n",
    "14. **idle_men** : The number of workers who were idle due to production interruption\n",
    "15. **actual_productivity** : The actual % of productivity that was delivered by the workers. It ranges from 0-1.\n",
    "\n",
    "### Libraries that can be used: numpy, scipy, pandas, scikit-learn, cvxpy, imbalanced-learn\n",
    "Any libraries used in the discussion materials are also allowed.\n",
    "\n",
    "#### Other Notes\n",
    "\n",
    " - Don't worry about not being able to achieve high accuracy, it is neither the goal nor the grading standard of this assignment. <br >\n",
    " - If not specified, you are not required to do hyperparameter tuning, but feel free to do so if you'd like.\n",
    "\n",
    "#### Trouble Shooting\n",
    "In case you have trouble installing and using imbalanced-learn(imblearn) <br >\n",
    "Run the below code cell, then go to the selection bar at top: Kernel > Restart. <br >\n",
    "Then try `import imblearn` to see if things work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: delayed in c:\\programdata\\anaconda3\\lib\\site-packages (0.11.0b1)\n",
      "Requirement already satisfied: hiredis in c:\\programdata\\anaconda3\\lib\\site-packages (from delayed) (2.0.0)\n",
      "Requirement already satisfied: redis in c:\\programdata\\anaconda3\\lib\\site-packages (from delayed) (3.5.3)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install imbalanced-learn delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Exercise 1 - General Data Preprocessing (20 points)\n",
    "\n",
    "Our dataset needs cleaning before building any models. Some of the cleaning tasks are common in general, but depends on what kind of models we are building, sometimes we have to do additional processing. These additional tasks will be mentioned in each of the remaining two exercises later.\n",
    "\n",
    "Note that **we will be using this processed data from exercise 1 in each of the remaining two exercises**.\n",
    "\n",
    "For convenience, here are the attributes that we would treat them as **categorical attributes**: `day`, `quarter`, `department`, and `team`. \n",
    "\n",
    " - Drop the column `date`.\n",
    " - For each of the categorical attributes, **print out** all the unique elements.\n",
    " - For each of the categorical attributes, remap the duplicated items, if you find there are typos or spaces among the duplicated items.\n",
    "     - For example, \"a\" and \"a \" should be the same, so we need to update \"a \" to be \"a\".\n",
    "     - Another example, \"apple\" and \"appel\" should be the same, so you should update \"appel\" to be \"apple\".\n",
    "     \n",
    "\n",
    " - Create another column named `satisfied` that records the productivity performance. The behavior defined as follows. **This is the dependent variable we'd like to classify in this assignment.**\n",
    "     - Return True or 1 if `actual_productivity` is equal to or greater than `targeted_productivity`. Otherwise, return False or 0, which means the team fails to meet the expected performance.\n",
    " - Drop the columns `actual_productivity` and `targeted_productivity`.\n",
    "\n",
    "\n",
    " - Find and **print out** which columns/attributes that have empty vaules, e.g., NA, NaN, null, None.\n",
    " - Fill the empty values with 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By Ofek Marom UCD\n",
      "For each of the categorical attributes, remove extra whitespace\n",
      "Drop the column date\n",
      "drop duplicates\n",
      "For each of the categorical attributes, **print out** all the unique elements\n",
      "['quarter1' 'quarter2' 'quarter3' 'quarter4' 'quarter5']\n",
      "['sweing' 'finishing']\n",
      "['thursday' 'saturday' 'sunday' 'monday' 'tuesday' 'wednesday']\n",
      "['8' '1' '11' '12' '6' '7' '2' '3' '9' '10' '5' '4']\n",
      "Create another column named `satisfied` that records the productivity performance\n",
      "Print all null in columns/attributes\n",
      "search nulls in  quarter\n",
      "search nulls in  department\n",
      "search nulls in  day\n",
      "search nulls in  team\n",
      "search nulls in  smv\n",
      "search nulls in  wip\n",
      "   * null was found in  wip  row =  1  and will modify with 0\n",
      "   * null was found in  wip  row =  6  and will modify with 0\n",
      "   * null was found in  wip  row =  13  and will modify with 0\n",
      "   * null was found in  wip  row =  14  and will modify with 0\n",
      "   * null was found in  wip  row =  15  and will modify with 0\n",
      "   * null was found in  wip  row =  16  and will modify with 0\n",
      "   * null was found in  wip  row =  18  and will modify with 0\n",
      "   * null was found in  wip  row =  19  and will modify with 0\n",
      "   * null was found in  wip  row =  20  and will modify with 0\n",
      "   * null was found in  wip  row =  21  and will modify with 0\n",
      "   * null was found in  wip  row =  22  and will modify with 0\n",
      "   * null was found in  wip  row =  23  and will modify with 0\n",
      "   * null was found in  wip  row =  33  and will modify with 0\n",
      "   * null was found in  wip  row =  35  and will modify with 0\n",
      "   * null was found in  wip  row =  38  and will modify with 0\n",
      "   * null was found in  wip  row =  39  and will modify with 0\n",
      "   * null was found in  wip  row =  40  and will modify with 0\n",
      "   * null was found in  wip  row =  41  and will modify with 0\n",
      "   * null was found in  wip  row =  42  and will modify with 0\n",
      "   * null was found in  wip  row =  44  and will modify with 0\n",
      "   * null was found in  wip  row =  52  and will modify with 0\n",
      "   * null was found in  wip  row =  53  and will modify with 0\n",
      "   * null was found in  wip  row =  57  and will modify with 0\n",
      "   * null was found in  wip  row =  58  and will modify with 0\n",
      "   * null was found in  wip  row =  60  and will modify with 0\n",
      "   * null was found in  wip  row =  61  and will modify with 0\n",
      "   * null was found in  wip  row =  62  and will modify with 0\n",
      "   * null was found in  wip  row =  63  and will modify with 0\n",
      "   * null was found in  wip  row =  64  and will modify with 0\n",
      "   * null was found in  wip  row =  66  and will modify with 0\n",
      "   * null was found in  wip  row =  67  and will modify with 0\n",
      "   * null was found in  wip  row =  76  and will modify with 0\n",
      "   * null was found in  wip  row =  77  and will modify with 0\n",
      "   * null was found in  wip  row =  80  and will modify with 0\n",
      "   * null was found in  wip  row =  81  and will modify with 0\n",
      "   * null was found in  wip  row =  83  and will modify with 0\n",
      "   * null was found in  wip  row =  84  and will modify with 0\n",
      "   * null was found in  wip  row =  85  and will modify with 0\n",
      "   * null was found in  wip  row =  86  and will modify with 0\n",
      "   * null was found in  wip  row =  87  and will modify with 0\n",
      "   * null was found in  wip  row =  90  and will modify with 0\n",
      "   * null was found in  wip  row =  91  and will modify with 0\n",
      "   * null was found in  wip  row =  101  and will modify with 0\n",
      "   * null was found in  wip  row =  103  and will modify with 0\n",
      "   * null was found in  wip  row =  104  and will modify with 0\n",
      "   * null was found in  wip  row =  105  and will modify with 0\n",
      "   * null was found in  wip  row =  109  and will modify with 0\n",
      "   * null was found in  wip  row =  110  and will modify with 0\n",
      "   * null was found in  wip  row =  111  and will modify with 0\n",
      "   * null was found in  wip  row =  112  and will modify with 0\n",
      "   * null was found in  wip  row =  113  and will modify with 0\n",
      "   * null was found in  wip  row =  122  and will modify with 0\n",
      "   * null was found in  wip  row =  123  and will modify with 0\n",
      "   * null was found in  wip  row =  125  and will modify with 0\n",
      "   * null was found in  wip  row =  126  and will modify with 0\n",
      "   * null was found in  wip  row =  127  and will modify with 0\n",
      "   * null was found in  wip  row =  129  and will modify with 0\n",
      "   * null was found in  wip  row =  134  and will modify with 0\n",
      "   * null was found in  wip  row =  135  and will modify with 0\n",
      "   * null was found in  wip  row =  141  and will modify with 0\n",
      "   * null was found in  wip  row =  142  and will modify with 0\n",
      "   * null was found in  wip  row =  143  and will modify with 0\n",
      "   * null was found in  wip  row =  144  and will modify with 0\n",
      "   * null was found in  wip  row =  145  and will modify with 0\n",
      "   * null was found in  wip  row =  148  and will modify with 0\n",
      "   * null was found in  wip  row =  149  and will modify with 0\n",
      "   * null was found in  wip  row =  150  and will modify with 0\n",
      "   * null was found in  wip  row =  151  and will modify with 0\n",
      "   * null was found in  wip  row =  155  and will modify with 0\n",
      "   * null was found in  wip  row =  156  and will modify with 0\n",
      "   * null was found in  wip  row =  157  and will modify with 0\n",
      "   * null was found in  wip  row =  166  and will modify with 0\n",
      "   * null was found in  wip  row =  167  and will modify with 0\n",
      "   * null was found in  wip  row =  169  and will modify with 0\n",
      "   * null was found in  wip  row =  170  and will modify with 0\n",
      "   * null was found in  wip  row =  171  and will modify with 0\n",
      "   * null was found in  wip  row =  173  and will modify with 0\n",
      "   * null was found in  wip  row =  174  and will modify with 0\n",
      "   * null was found in  wip  row =  178  and will modify with 0\n",
      "   * null was found in  wip  row =  179  and will modify with 0\n",
      "   * null was found in  wip  row =  185  and will modify with 0\n",
      "   * null was found in  wip  row =  186  and will modify with 0\n",
      "   * null was found in  wip  row =  187  and will modify with 0\n",
      "   * null was found in  wip  row =  189  and will modify with 0\n",
      "   * null was found in  wip  row =  190  and will modify with 0\n",
      "   * null was found in  wip  row =  193  and will modify with 0\n",
      "   * null was found in  wip  row =  194  and will modify with 0\n",
      "   * null was found in  wip  row =  195  and will modify with 0\n",
      "   * null was found in  wip  row =  196  and will modify with 0\n",
      "   * null was found in  wip  row =  197  and will modify with 0\n",
      "   * null was found in  wip  row =  202  and will modify with 0\n",
      "   * null was found in  wip  row =  203  and will modify with 0\n",
      "   * null was found in  wip  row =  208  and will modify with 0\n",
      "   * null was found in  wip  row =  212  and will modify with 0\n",
      "   * null was found in  wip  row =  213  and will modify with 0\n",
      "   * null was found in  wip  row =  215  and will modify with 0\n",
      "   * null was found in  wip  row =  216  and will modify with 0\n",
      "   * null was found in  wip  row =  217  and will modify with 0\n",
      "   * null was found in  wip  row =  218  and will modify with 0\n",
      "   * null was found in  wip  row =  219  and will modify with 0\n",
      "   * null was found in  wip  row =  220  and will modify with 0\n",
      "   * null was found in  wip  row =  225  and will modify with 0\n",
      "   * null was found in  wip  row =  226  and will modify with 0\n",
      "   * null was found in  wip  row =  231  and will modify with 0\n",
      "   * null was found in  wip  row =  232  and will modify with 0\n",
      "   * null was found in  wip  row =  233  and will modify with 0\n",
      "   * null was found in  wip  row =  238  and will modify with 0\n",
      "   * null was found in  wip  row =  239  and will modify with 0\n",
      "   * null was found in  wip  row =  241  and will modify with 0\n",
      "   * null was found in  wip  row =  242  and will modify with 0\n",
      "   * null was found in  wip  row =  243  and will modify with 0\n",
      "   * null was found in  wip  row =  246  and will modify with 0\n",
      "   * null was found in  wip  row =  247  and will modify with 0\n",
      "   * null was found in  wip  row =  252  and will modify with 0\n",
      "   * null was found in  wip  row =  256  and will modify with 0\n",
      "   * null was found in  wip  row =  258  and will modify with 0\n",
      "   * null was found in  wip  row =  259  and will modify with 0\n",
      "   * null was found in  wip  row =  260  and will modify with 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   * null was found in  wip  row =  261  and will modify with 0\n",
      "   * null was found in  wip  row =  262  and will modify with 0\n",
      "   * null was found in  wip  row =  263  and will modify with 0\n",
      "   * null was found in  wip  row =  271  and will modify with 0\n",
      "   * null was found in  wip  row =  274  and will modify with 0\n",
      "   * null was found in  wip  row =  278  and will modify with 0\n",
      "   * null was found in  wip  row =  279  and will modify with 0\n",
      "   * null was found in  wip  row =  280  and will modify with 0\n",
      "   * null was found in  wip  row =  281  and will modify with 0\n",
      "   * null was found in  wip  row =  282  and will modify with 0\n",
      "   * null was found in  wip  row =  291  and will modify with 0\n",
      "   * null was found in  wip  row =  292  and will modify with 0\n",
      "   * null was found in  wip  row =  296  and will modify with 0\n",
      "   * null was found in  wip  row =  298  and will modify with 0\n",
      "   * null was found in  wip  row =  299  and will modify with 0\n",
      "   * null was found in  wip  row =  300  and will modify with 0\n",
      "   * null was found in  wip  row =  301  and will modify with 0\n",
      "   * null was found in  wip  row =  308  and will modify with 0\n",
      "   * null was found in  wip  row =  313  and will modify with 0\n",
      "   * null was found in  wip  row =  315  and will modify with 0\n",
      "   * null was found in  wip  row =  317  and will modify with 0\n",
      "   * null was found in  wip  row =  318  and will modify with 0\n",
      "   * null was found in  wip  row =  319  and will modify with 0\n",
      "   * null was found in  wip  row =  320  and will modify with 0\n",
      "   * null was found in  wip  row =  324  and will modify with 0\n",
      "   * null was found in  wip  row =  330  and will modify with 0\n",
      "   * null was found in  wip  row =  334  and will modify with 0\n",
      "   * null was found in  wip  row =  335  and will modify with 0\n",
      "   * null was found in  wip  row =  337  and will modify with 0\n",
      "   * null was found in  wip  row =  345  and will modify with 0\n",
      "   * null was found in  wip  row =  348  and will modify with 0\n",
      "   * null was found in  wip  row =  351  and will modify with 0\n",
      "   * null was found in  wip  row =  352  and will modify with 0\n",
      "   * null was found in  wip  row =  353  and will modify with 0\n",
      "   * null was found in  wip  row =  356  and will modify with 0\n",
      "   * null was found in  wip  row =  360  and will modify with 0\n",
      "   * null was found in  wip  row =  366  and will modify with 0\n",
      "   * null was found in  wip  row =  368  and will modify with 0\n",
      "   * null was found in  wip  row =  370  and will modify with 0\n",
      "   * null was found in  wip  row =  371  and will modify with 0\n",
      "   * null was found in  wip  row =  372  and will modify with 0\n",
      "   * null was found in  wip  row =  379  and will modify with 0\n",
      "   * null was found in  wip  row =  382  and will modify with 0\n",
      "   * null was found in  wip  row =  383  and will modify with 0\n",
      "   * null was found in  wip  row =  384  and will modify with 0\n",
      "   * null was found in  wip  row =  385  and will modify with 0\n",
      "   * null was found in  wip  row =  390  and will modify with 0\n",
      "   * null was found in  wip  row =  391  and will modify with 0\n",
      "   * null was found in  wip  row =  392  and will modify with 0\n",
      "   * null was found in  wip  row =  393  and will modify with 0\n",
      "   * null was found in  wip  row =  394  and will modify with 0\n",
      "   * null was found in  wip  row =  395  and will modify with 0\n",
      "   * null was found in  wip  row =  398  and will modify with 0\n",
      "   * null was found in  wip  row =  399  and will modify with 0\n",
      "   * null was found in  wip  row =  400  and will modify with 0\n",
      "   * null was found in  wip  row =  401  and will modify with 0\n",
      "   * null was found in  wip  row =  409  and will modify with 0\n",
      "   * null was found in  wip  row =  412  and will modify with 0\n",
      "   * null was found in  wip  row =  413  and will modify with 0\n",
      "   * null was found in  wip  row =  415  and will modify with 0\n",
      "   * null was found in  wip  row =  416  and will modify with 0\n",
      "   * null was found in  wip  row =  417  and will modify with 0\n",
      "   * null was found in  wip  row =  418  and will modify with 0\n",
      "   * null was found in  wip  row =  419  and will modify with 0\n",
      "   * null was found in  wip  row =  420  and will modify with 0\n",
      "   * null was found in  wip  row =  421  and will modify with 0\n",
      "   * null was found in  wip  row =  428  and will modify with 0\n",
      "   * null was found in  wip  row =  433  and will modify with 0\n",
      "   * null was found in  wip  row =  436  and will modify with 0\n",
      "   * null was found in  wip  row =  437  and will modify with 0\n",
      "   * null was found in  wip  row =  438  and will modify with 0\n",
      "   * null was found in  wip  row =  439  and will modify with 0\n",
      "   * null was found in  wip  row =  440  and will modify with 0\n",
      "   * null was found in  wip  row =  441  and will modify with 0\n",
      "   * null was found in  wip  row =  442  and will modify with 0\n",
      "   * null was found in  wip  row =  449  and will modify with 0\n",
      "   * null was found in  wip  row =  453  and will modify with 0\n",
      "   * null was found in  wip  row =  458  and will modify with 0\n",
      "   * null was found in  wip  row =  459  and will modify with 0\n",
      "   * null was found in  wip  row =  460  and will modify with 0\n",
      "   * null was found in  wip  row =  462  and will modify with 0\n",
      "   * null was found in  wip  row =  464  and will modify with 0\n",
      "   * null was found in  wip  row =  465  and will modify with 0\n",
      "   * null was found in  wip  row =  466  and will modify with 0\n",
      "   * null was found in  wip  row =  468  and will modify with 0\n",
      "   * null was found in  wip  row =  469  and will modify with 0\n",
      "   * null was found in  wip  row =  474  and will modify with 0\n",
      "   * null was found in  wip  row =  479  and will modify with 0\n",
      "   * null was found in  wip  row =  480  and will modify with 0\n",
      "   * null was found in  wip  row =  481  and will modify with 0\n",
      "   * null was found in  wip  row =  484  and will modify with 0\n",
      "   * null was found in  wip  row =  487  and will modify with 0\n",
      "   * null was found in  wip  row =  490  and will modify with 0\n",
      "   * null was found in  wip  row =  491  and will modify with 0\n",
      "   * null was found in  wip  row =  495  and will modify with 0\n",
      "   * null was found in  wip  row =  497  and will modify with 0\n",
      "   * null was found in  wip  row =  499  and will modify with 0\n",
      "   * null was found in  wip  row =  503  and will modify with 0\n",
      "   * null was found in  wip  row =  504  and will modify with 0\n",
      "   * null was found in  wip  row =  505  and will modify with 0\n",
      "   * null was found in  wip  row =  506  and will modify with 0\n",
      "   * null was found in  wip  row =  507  and will modify with 0\n",
      "   * null was found in  wip  row =  511  and will modify with 0\n",
      "   * null was found in  wip  row =  513  and will modify with 0\n",
      "   * null was found in  wip  row =  516  and will modify with 0\n",
      "   * null was found in  wip  row =  520  and will modify with 0\n",
      "   * null was found in  wip  row =  521  and will modify with 0\n",
      "   * null was found in  wip  row =  522  and will modify with 0\n",
      "   * null was found in  wip  row =  523  and will modify with 0\n",
      "   * null was found in  wip  row =  524  and will modify with 0\n",
      "   * null was found in  wip  row =  525  and will modify with 0\n",
      "   * null was found in  wip  row =  526  and will modify with 0\n",
      "   * null was found in  wip  row =  527  and will modify with 0\n",
      "   * null was found in  wip  row =  528  and will modify with 0\n",
      "   * null was found in  wip  row =  529  and will modify with 0\n",
      "   * null was found in  wip  row =  530  and will modify with 0\n",
      "   * null was found in  wip  row =  531  and will modify with 0\n",
      "   * null was found in  wip  row =  542  and will modify with 0\n",
      "   * null was found in  wip  row =  545  and will modify with 0\n",
      "   * null was found in  wip  row =  547  and will modify with 0\n",
      "   * null was found in  wip  row =  548  and will modify with 0\n",
      "   * null was found in  wip  row =  549  and will modify with 0\n",
      "   * null was found in  wip  row =  552  and will modify with 0\n",
      "   * null was found in  wip  row =  555  and will modify with 0\n",
      "   * null was found in  wip  row =  560  and will modify with 0\n",
      "   * null was found in  wip  row =  562  and will modify with 0\n",
      "   * null was found in  wip  row =  566  and will modify with 0\n",
      "   * null was found in  wip  row =  567  and will modify with 0\n",
      "   * null was found in  wip  row =  571  and will modify with 0\n",
      "   * null was found in  wip  row =  574  and will modify with 0\n",
      "   * null was found in  wip  row =  575  and will modify with 0\n",
      "   * null was found in  wip  row =  578  and will modify with 0\n",
      "   * null was found in  wip  row =  580  and will modify with 0\n",
      "   * null was found in  wip  row =  583  and will modify with 0\n",
      "   * null was found in  wip  row =  584  and will modify with 0\n",
      "   * null was found in  wip  row =  587  and will modify with 0\n",
      "   * null was found in  wip  row =  590  and will modify with 0\n",
      "   * null was found in  wip  row =  596  and will modify with 0\n",
      "   * null was found in  wip  row =  597  and will modify with 0\n",
      "   * null was found in  wip  row =  602  and will modify with 0\n",
      "   * null was found in  wip  row =  603  and will modify with 0\n",
      "   * null was found in  wip  row =  604  and will modify with 0\n",
      "   * null was found in  wip  row =  608  and will modify with 0\n",
      "   * null was found in  wip  row =  609  and will modify with 0\n",
      "   * null was found in  wip  row =  614  and will modify with 0\n",
      "   * null was found in  wip  row =  616  and will modify with 0\n",
      "   * null was found in  wip  row =  621  and will modify with 0\n",
      "   * null was found in  wip  row =  623  and will modify with 0\n",
      "   * null was found in  wip  row =  624  and will modify with 0\n",
      "   * null was found in  wip  row =  625  and will modify with 0\n",
      "   * null was found in  wip  row =  626  and will modify with 0\n",
      "   * null was found in  wip  row =  629  and will modify with 0\n",
      "   * null was found in  wip  row =  636  and will modify with 0\n",
      "   * null was found in  wip  row =  641  and will modify with 0\n",
      "   * null was found in  wip  row =  642  and will modify with 0\n",
      "   * null was found in  wip  row =  643  and will modify with 0\n",
      "   * null was found in  wip  row =  646  and will modify with 0\n",
      "   * null was found in  wip  row =  649  and will modify with 0\n",
      "   * null was found in  wip  row =  653  and will modify with 0\n",
      "   * null was found in  wip  row =  656  and will modify with 0\n",
      "   * null was found in  wip  row =  660  and will modify with 0\n",
      "   * null was found in  wip  row =  661  and will modify with 0\n",
      "   * null was found in  wip  row =  662  and will modify with 0\n",
      "   * null was found in  wip  row =  663  and will modify with 0\n",
      "   * null was found in  wip  row =  669  and will modify with 0\n",
      "   * null was found in  wip  row =  670  and will modify with 0\n",
      "   * null was found in  wip  row =  674  and will modify with 0\n",
      "   * null was found in  wip  row =  675  and will modify with 0\n",
      "   * null was found in  wip  row =  679  and will modify with 0\n",
      "   * null was found in  wip  row =  685  and will modify with 0\n",
      "   * null was found in  wip  row =  687  and will modify with 0\n",
      "   * null was found in  wip  row =  691  and will modify with 0\n",
      "   * null was found in  wip  row =  692  and will modify with 0\n",
      "   * null was found in  wip  row =  693  and will modify with 0\n",
      "   * null was found in  wip  row =  698  and will modify with 0\n",
      "   * null was found in  wip  row =  701  and will modify with 0\n",
      "   * null was found in  wip  row =  705  and will modify with 0\n",
      "   * null was found in  wip  row =  707  and will modify with 0\n",
      "   * null was found in  wip  row =  708  and will modify with 0\n",
      "   * null was found in  wip  row =  711  and will modify with 0\n",
      "   * null was found in  wip  row =  712  and will modify with 0\n",
      "   * null was found in  wip  row =  715  and will modify with 0\n",
      "   * null was found in  wip  row =  716  and will modify with 0\n",
      "   * null was found in  wip  row =  717  and will modify with 0\n",
      "   * null was found in  wip  row =  725  and will modify with 0\n",
      "   * null was found in  wip  row =  727  and will modify with 0\n",
      "   * null was found in  wip  row =  731  and will modify with 0\n",
      "   * null was found in  wip  row =  733  and will modify with 0\n",
      "   * null was found in  wip  row =  735  and will modify with 0\n",
      "   * null was found in  wip  row =  738  and will modify with 0\n",
      "   * null was found in  wip  row =  739  and will modify with 0\n",
      "   * null was found in  wip  row =  741  and will modify with 0\n",
      "   * null was found in  wip  row =  742  and will modify with 0\n",
      "   * null was found in  wip  row =  750  and will modify with 0\n",
      "   * null was found in  wip  row =  751  and will modify with 0\n",
      "   * null was found in  wip  row =  752  and will modify with 0\n",
      "   * null was found in  wip  row =  755  and will modify with 0\n",
      "   * null was found in  wip  row =  758  and will modify with 0\n",
      "   * null was found in  wip  row =  764  and will modify with 0\n",
      "   * null was found in  wip  row =  765  and will modify with 0\n",
      "   * null was found in  wip  row =  766  and will modify with 0\n",
      "   * null was found in  wip  row =  767  and will modify with 0\n",
      "   * null was found in  wip  row =  769  and will modify with 0\n",
      "   * null was found in  wip  row =  771  and will modify with 0\n",
      "   * null was found in  wip  row =  773  and will modify with 0\n",
      "   * null was found in  wip  row =  778  and will modify with 0\n",
      "   * null was found in  wip  row =  779  and will modify with 0\n",
      "   * null was found in  wip  row =  783  and will modify with 0\n",
      "   * null was found in  wip  row =  786  and will modify with 0\n",
      "   * null was found in  wip  row =  787  and will modify with 0\n",
      "   * null was found in  wip  row =  788  and will modify with 0\n",
      "   * null was found in  wip  row =  792  and will modify with 0\n",
      "   * null was found in  wip  row =  795  and will modify with 0\n",
      "   * null was found in  wip  row =  797  and will modify with 0\n",
      "   * null was found in  wip  row =  802  and will modify with 0\n",
      "   * null was found in  wip  row =  804  and will modify with 0\n",
      "   * null was found in  wip  row =  805  and will modify with 0\n",
      "   * null was found in  wip  row =  806  and will modify with 0\n",
      "   * null was found in  wip  row =  808  and will modify with 0\n",
      "   * null was found in  wip  row =  811  and will modify with 0\n",
      "   * null was found in  wip  row =  815  and will modify with 0\n",
      "   * null was found in  wip  row =  819  and will modify with 0\n",
      "   * null was found in  wip  row =  820  and will modify with 0\n",
      "   * null was found in  wip  row =  823  and will modify with 0\n",
      "   * null was found in  wip  row =  824  and will modify with 0\n",
      "   * null was found in  wip  row =  825  and will modify with 0\n",
      "   * null was found in  wip  row =  833  and will modify with 0\n",
      "   * null was found in  wip  row =  836  and will modify with 0\n",
      "   * null was found in  wip  row =  837  and will modify with 0\n",
      "   * null was found in  wip  row =  838  and will modify with 0\n",
      "   * null was found in  wip  row =  839  and will modify with 0\n",
      "   * null was found in  wip  row =  842  and will modify with 0\n",
      "   * null was found in  wip  row =  844  and will modify with 0\n",
      "   * null was found in  wip  row =  849  and will modify with 0\n",
      "   * null was found in  wip  row =  851  and will modify with 0\n",
      "   * null was found in  wip  row =  852  and will modify with 0\n",
      "   * null was found in  wip  row =  856  and will modify with 0\n",
      "   * null was found in  wip  row =  857  and will modify with 0\n",
      "   * null was found in  wip  row =  859  and will modify with 0\n",
      "   * null was found in  wip  row =  861  and will modify with 0\n",
      "   * null was found in  wip  row =  864  and will modify with 0\n",
      "   * null was found in  wip  row =  865  and will modify with 0\n",
      "   * null was found in  wip  row =  866  and will modify with 0\n",
      "   * null was found in  wip  row =  867  and will modify with 0\n",
      "   * null was found in  wip  row =  870  and will modify with 0\n",
      "   * null was found in  wip  row =  871  and will modify with 0\n",
      "   * null was found in  wip  row =  873  and will modify with 0\n",
      "   * null was found in  wip  row =  881  and will modify with 0\n",
      "   * null was found in  wip  row =  883  and will modify with 0\n",
      "   * null was found in  wip  row =  884  and will modify with 0\n",
      "   * null was found in  wip  row =  885  and will modify with 0\n",
      "   * null was found in  wip  row =  886  and will modify with 0\n",
      "   * null was found in  wip  row =  887  and will modify with 0\n",
      "   * null was found in  wip  row =  899  and will modify with 0\n",
      "   * null was found in  wip  row =  900  and will modify with 0\n",
      "   * null was found in  wip  row =  901  and will modify with 0\n",
      "   * null was found in  wip  row =  902  and will modify with 0\n",
      "   * null was found in  wip  row =  903  and will modify with 0\n",
      "   * null was found in  wip  row =  904  and will modify with 0\n",
      "   * null was found in  wip  row =  908  and will modify with 0\n",
      "   * null was found in  wip  row =  913  and will modify with 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   * null was found in  wip  row =  914  and will modify with 0\n",
      "   * null was found in  wip  row =  918  and will modify with 0\n",
      "   * null was found in  wip  row =  920  and will modify with 0\n",
      "   * null was found in  wip  row =  923  and will modify with 0\n",
      "   * null was found in  wip  row =  924  and will modify with 0\n",
      "   * null was found in  wip  row =  925  and will modify with 0\n",
      "   * null was found in  wip  row =  926  and will modify with 0\n",
      "   * null was found in  wip  row =  936  and will modify with 0\n",
      "   * null was found in  wip  row =  937  and will modify with 0\n",
      "   * null was found in  wip  row =  940  and will modify with 0\n",
      "   * null was found in  wip  row =  941  and will modify with 0\n",
      "   * null was found in  wip  row =  942  and will modify with 0\n",
      "   * null was found in  wip  row =  943  and will modify with 0\n",
      "   * null was found in  wip  row =  944  and will modify with 0\n",
      "   * null was found in  wip  row =  948  and will modify with 0\n",
      "   * null was found in  wip  row =  955  and will modify with 0\n",
      "   * null was found in  wip  row =  956  and will modify with 0\n",
      "   * null was found in  wip  row =  959  and will modify with 0\n",
      "   * null was found in  wip  row =  960  and will modify with 0\n",
      "   * null was found in  wip  row =  962  and will modify with 0\n",
      "   * null was found in  wip  row =  963  and will modify with 0\n",
      "   * null was found in  wip  row =  964  and will modify with 0\n",
      "   * null was found in  wip  row =  965  and will modify with 0\n",
      "   * null was found in  wip  row =  969  and will modify with 0\n",
      "   * null was found in  wip  row =  976  and will modify with 0\n",
      "   * null was found in  wip  row =  977  and will modify with 0\n",
      "   * null was found in  wip  row =  981  and will modify with 0\n",
      "   * null was found in  wip  row =  982  and will modify with 0\n",
      "   * null was found in  wip  row =  983  and will modify with 0\n",
      "   * null was found in  wip  row =  984  and will modify with 0\n",
      "   * null was found in  wip  row =  985  and will modify with 0\n",
      "   * null was found in  wip  row =  986  and will modify with 0\n",
      "   * null was found in  wip  row =  997  and will modify with 0\n",
      "   * null was found in  wip  row =  998  and will modify with 0\n",
      "   * null was found in  wip  row =  1000  and will modify with 0\n",
      "   * null was found in  wip  row =  1002  and will modify with 0\n",
      "   * null was found in  wip  row =  1003  and will modify with 0\n",
      "   * null was found in  wip  row =  1004  and will modify with 0\n",
      "   * null was found in  wip  row =  1005  and will modify with 0\n",
      "   * null was found in  wip  row =  1006  and will modify with 0\n",
      "   * null was found in  wip  row =  1007  and will modify with 0\n",
      "   * null was found in  wip  row =  1010  and will modify with 0\n",
      "   * null was found in  wip  row =  1014  and will modify with 0\n",
      "   * null was found in  wip  row =  1021  and will modify with 0\n",
      "   * null was found in  wip  row =  1022  and will modify with 0\n",
      "   * null was found in  wip  row =  1023  and will modify with 0\n",
      "   * null was found in  wip  row =  1024  and will modify with 0\n",
      "   * null was found in  wip  row =  1025  and will modify with 0\n",
      "   * null was found in  wip  row =  1026  and will modify with 0\n",
      "   * null was found in  wip  row =  1036  and will modify with 0\n",
      "   * null was found in  wip  row =  1039  and will modify with 0\n",
      "   * null was found in  wip  row =  1040  and will modify with 0\n",
      "   * null was found in  wip  row =  1041  and will modify with 0\n",
      "   * null was found in  wip  row =  1042  and will modify with 0\n",
      "   * null was found in  wip  row =  1043  and will modify with 0\n",
      "   * null was found in  wip  row =  1044  and will modify with 0\n",
      "   * null was found in  wip  row =  1045  and will modify with 0\n",
      "   * null was found in  wip  row =  1047  and will modify with 0\n",
      "   * null was found in  wip  row =  1048  and will modify with 0\n",
      "   * null was found in  wip  row =  1049  and will modify with 0\n",
      "   * null was found in  wip  row =  1050  and will modify with 0\n",
      "   * null was found in  wip  row =  1051  and will modify with 0\n",
      "   * null was found in  wip  row =  1052  and will modify with 0\n",
      "   * null was found in  wip  row =  1062  and will modify with 0\n",
      "   * null was found in  wip  row =  1063  and will modify with 0\n",
      "   * null was found in  wip  row =  1064  and will modify with 0\n",
      "   * null was found in  wip  row =  1068  and will modify with 0\n",
      "   * null was found in  wip  row =  1069  and will modify with 0\n",
      "   * null was found in  wip  row =  1070  and will modify with 0\n",
      "   * null was found in  wip  row =  1071  and will modify with 0\n",
      "   * null was found in  wip  row =  1072  and will modify with 0\n",
      "   * null was found in  wip  row =  1073  and will modify with 0\n",
      "   * null was found in  wip  row =  1074  and will modify with 0\n",
      "   * null was found in  wip  row =  1084  and will modify with 0\n",
      "   * null was found in  wip  row =  1087  and will modify with 0\n",
      "   * null was found in  wip  row =  1090  and will modify with 0\n",
      "   * null was found in  wip  row =  1091  and will modify with 0\n",
      "   * null was found in  wip  row =  1095  and will modify with 0\n",
      "   * null was found in  wip  row =  1098  and will modify with 0\n",
      "   * null was found in  wip  row =  1099  and will modify with 0\n",
      "   * null was found in  wip  row =  1100  and will modify with 0\n",
      "   * null was found in  wip  row =  1102  and will modify with 0\n",
      "   * null was found in  wip  row =  1103  and will modify with 0\n",
      "   * null was found in  wip  row =  1106  and will modify with 0\n",
      "   * null was found in  wip  row =  1107  and will modify with 0\n",
      "   * null was found in  wip  row =  1108  and will modify with 0\n",
      "   * null was found in  wip  row =  1109  and will modify with 0\n",
      "   * null was found in  wip  row =  1110  and will modify with 0\n",
      "   * null was found in  wip  row =  1111  and will modify with 0\n",
      "   * null was found in  wip  row =  1112  and will modify with 0\n",
      "   * null was found in  wip  row =  1118  and will modify with 0\n",
      "   * null was found in  wip  row =  1125  and will modify with 0\n",
      "   * null was found in  wip  row =  1126  and will modify with 0\n",
      "   * null was found in  wip  row =  1127  and will modify with 0\n",
      "   * null was found in  wip  row =  1128  and will modify with 0\n",
      "   * null was found in  wip  row =  1129  and will modify with 0\n",
      "   * null was found in  wip  row =  1130  and will modify with 0\n",
      "   * null was found in  wip  row =  1133  and will modify with 0\n",
      "   * null was found in  wip  row =  1137  and will modify with 0\n",
      "   * null was found in  wip  row =  1138  and will modify with 0\n",
      "   * null was found in  wip  row =  1139  and will modify with 0\n",
      "   * null was found in  wip  row =  1143  and will modify with 0\n",
      "   * null was found in  wip  row =  1148  and will modify with 0\n",
      "   * null was found in  wip  row =  1149  and will modify with 0\n",
      "   * null was found in  wip  row =  1150  and will modify with 0\n",
      "   * null was found in  wip  row =  1151  and will modify with 0\n",
      "   * null was found in  wip  row =  1153  and will modify with 0\n",
      "   * null was found in  wip  row =  1154  and will modify with 0\n",
      "   * null was found in  wip  row =  1155  and will modify with 0\n",
      "   * null was found in  wip  row =  1157  and will modify with 0\n",
      "   * null was found in  wip  row =  1161  and will modify with 0\n",
      "   * null was found in  wip  row =  1164  and will modify with 0\n",
      "   * null was found in  wip  row =  1170  and will modify with 0\n",
      "   * null was found in  wip  row =  1171  and will modify with 0\n",
      "   * null was found in  wip  row =  1172  and will modify with 0\n",
      "   * null was found in  wip  row =  1173  and will modify with 0\n",
      "   * null was found in  wip  row =  1174  and will modify with 0\n",
      "   * null was found in  wip  row =  1175  and will modify with 0\n",
      "   * null was found in  wip  row =  1176  and will modify with 0\n",
      "   * null was found in  wip  row =  1177  and will modify with 0\n",
      "   * null was found in  wip  row =  1181  and will modify with 0\n",
      "   * null was found in  wip  row =  1182  and will modify with 0\n",
      "   * null was found in  wip  row =  1192  and will modify with 0\n",
      "   * null was found in  wip  row =  1193  and will modify with 0\n",
      "   * null was found in  wip  row =  1194  and will modify with 0\n",
      "   * null was found in  wip  row =  1195  and will modify with 0\n",
      "   * null was found in  wip  row =  1196  and will modify with 0\n",
      "search nulls in  over_time\n",
      "search nulls in  incentive\n",
      "search nulls in  idle_time\n",
      "search nulls in  idle_men\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search nulls in  no_of_style_change\n",
      "search nulls in  no_of_workers\n",
      "search nulls in  satisfied\n",
      "fill and replace all NA, NaN, null, None with 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "      <th>satisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>12</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quarter department       day team    smv     wip over_time incentive  \\\n",
       "0  quarter1     sweing  thursday    8  26.16  1108.0      7080        98   \n",
       "1  quarter1  finishing  thursday    1   3.94       0       960         0   \n",
       "2  quarter1     sweing  thursday   11  11.41   968.0      3660        50   \n",
       "3  quarter1     sweing  thursday   12  11.41   968.0      3660        50   \n",
       "4  quarter1     sweing  thursday    6   25.9  1170.0      1920        50   \n",
       "\n",
       "  idle_time idle_men no_of_style_change no_of_workers  satisfied  \n",
       "0       0.0        0                  0          59.0          1  \n",
       "1       0.0        0                  0           8.0          1  \n",
       "2       0.0        0                  0          30.5          1  \n",
       "3       0.0        0                  0          30.5          1  \n",
       "4       0.0        0                  0          56.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print('By Ofek Marom UCD')\n",
    "\n",
    "# Step 1: reading csv file and at a same time using skipinitial attribute which will remove extra space\n",
    "df = pd.read_csv('garments_worker_productivity.csv',skipinitialspace = True)\n",
    "\n",
    "categorical_attributes = ['quarter','department','day','team']\n",
    "\n",
    "# Step 2: convert all text to low case\n",
    "df = df.astype(str).apply(lambda x: x.str.lower())\n",
    "#display(df.head())\n",
    "#  Step 3: remove extra whitespace\n",
    "print('For each of the categorical attributes, remove extra whitespace')\n",
    "for col in categorical_attributes:\n",
    "    df[col] = df[col].str.strip()\n",
    "\n",
    "# Step 4: Drop the column date\n",
    "print('Drop the column date')\n",
    "del df['date']\n",
    "#display(df.head())\n",
    "# Step 5: drop duplicates\n",
    "print('drop duplicates')\n",
    "df = df.drop_duplicates() # drop all duplicate records\n",
    "#display(df.head())\n",
    "# Step 6: print unique categorical_attributes\n",
    "print('For each of the categorical attributes, **print out** all the unique elements')\n",
    "df['quarter']\n",
    "for col in categorical_attributes:\n",
    "    print(df[col].unique())\n",
    "    \n",
    "    \n",
    "#Step 7: Create another column named `satisfied` that records the productivity performanc\n",
    "print('Create another column named `satisfied` that records the productivity performance')\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    (df['targeted_productivity'] > df['actual_productivity'] ),\n",
    "    (df['targeted_productivity'] <= df['actual_productivity'] )\n",
    "    ]\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [0,1]\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['satisfied'] = np.select(conditions, values)\n",
    "\n",
    "#Drop the columns actual_productivity and targeted_productivity.\n",
    "del df['actual_productivity']\n",
    "del df['targeted_productivity']\n",
    "\n",
    "print('Print all null in columns/attributes')\n",
    "No_Data_symbol_list = ['na','nan','null','none'] #generate list for all symbol represent no data\n",
    "for col in df:\n",
    "    print('search nulls in ',col)\n",
    "    for index in range(len(df[col])):\n",
    "      if df[col][index] in No_Data_symbol_list: # check if symbol in df[col][index] contain no data symbol \n",
    "        print('   * null was found in ',col,' row = ',index,' and will modify with 0')\n",
    "\n",
    "# Step 8: fill and replace all NA, NaN, null, None with 0\n",
    "print(\"fill and replace all NA, NaN, null, None with 0\")\n",
    "df = df.replace('na', 0)\n",
    "df = df.replace('nan', 0)\n",
    "df = df.replace('null', 0)\n",
    "df = df.replace('none', 0)\n",
    "df = df.fillna(0)    \n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Na√Øve Bayes Classifier (40 points in total)\n",
    "\n",
    "### Exercise 2.1 - Additional Data Preprocessing (10 points)\n",
    "\n",
    "To build a Na√Øve Bayes Classifier, we need to further encode our categorical variables.\n",
    "\n",
    " - For each of the **categorical attribtues**, encode the set of categories to be **0 ~ (n_classes - 1)**.\n",
    "     - For example, \\[\"paris\", \"paris\", \"tokyo\", \"amsterdam\"\\] should be encoded as \\[1, 1, 2, 0\\].\n",
    "     - Note that the order does not really matter, i.e., \\[0, 0, 1, 2\\] also works. But you have to start with 0 in your encodings.\n",
    "     - You can find information about this encoding in the discussion materials.\n",
    "\n",
    "\n",
    " - Split the data into training and testing set with the ratio of 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remape atributes: quarter,department and day\n",
      "remape atributes team: team = team - 1, so team will start from 0 to 11\n",
      "Data prior encoding\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "      <th>satisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>12</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quarter department       day team    smv     wip over_time incentive  \\\n",
       "0  quarter1     sweing  thursday    8  26.16  1108.0      7080        98   \n",
       "1  quarter1  finishing  thursday    1   3.94       0       960         0   \n",
       "2  quarter1     sweing  thursday   11  11.41   968.0      3660        50   \n",
       "3  quarter1     sweing  thursday   12  11.41   968.0      3660        50   \n",
       "4  quarter1     sweing  thursday    6   25.9  1170.0      1920        50   \n",
       "\n",
       "  idle_time idle_men no_of_style_change no_of_workers  satisfied  \n",
       "0       0.0        0                  0          59.0          1  \n",
       "1       0.0        0                  0           8.0          1  \n",
       "2       0.0        0                  0          30.5          1  \n",
       "3       0.0        0                  0          30.5          1  \n",
       "4       0.0        0                  0          56.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data post encoding\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "      <th>satisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quarter  department  day  team    smv     wip over_time incentive  \\\n",
       "0        0           0    3     7  26.16  1108.0      7080        98   \n",
       "1        0           1    3     0   3.94       0       960         0   \n",
       "2        0           0    3    10  11.41   968.0      3660        50   \n",
       "3        0           0    3    11  11.41   968.0      3660        50   \n",
       "4        0           0    3     5   25.9  1170.0      1920        50   \n",
       "\n",
       "  idle_time idle_men no_of_style_change no_of_workers  satisfied  \n",
       "0       0.0        0                  0          59.0          1  \n",
       "1       0.0        0                  0           8.0          1  \n",
       "2       0.0        0                  0          30.5          1  \n",
       "3       0.0        0                  0          30.5          1  \n",
       "4       0.0        0                  0          56.0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For each of the categorical attribtues, encode the set of categories to be 0 ~ (n_classes - 1).\n",
    "#### OrdinalEncoding ====\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Manual Mapping = 'team' will get special treatment => (team = team - 1)\n",
    "remap = {\n",
    "    'quarter': {'quarter1': 0,'quarter2': 1, 'quarter3': 2, 'quarter4': 3,'quarter5':4},\n",
    "    'department': {'sweing': 0,'finishing': 1},\n",
    "    'day': {'monday': 0, 'tuesday': 1, 'wednesday': 2, 'thursday': 3,'friday':4,'saturday':5,'sunday':6},\n",
    "}\n",
    "\n",
    "df1 = df.replace(remap) # encode all categorical attribtues\n",
    "print('remape atributes: quarter,department and day')\n",
    "# -- special treatment to team -> we will reduce 1 from all team data so (1-12) range will be transfer to => (0-11)\n",
    "df1['team'] = df['team'].astype(int) - 1\n",
    "print('remape atributes team: team = team - 1, so team will start from 0 to 11')\n",
    "\n",
    "print('Data prior encoding')\n",
    "display(df.head())\n",
    "print('Data post encoding')\n",
    "display(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- split data 80/20 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    703\n",
       "0    254\n",
       "Name: satisfied, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data into training and testing set with the ratio of 80:20.\n",
    "train, test = train_test_split(df1, test_size=0.2, random_state=21)\n",
    "\n",
    "#--- split data 80/20 ---\n",
    "print('--- split data 80/20 ---')\n",
    "X_train_org, y_train = train.copy().drop(columns=['satisfied']), train['satisfied']\n",
    "X_test_org, y_test = test.copy().drop(columns=['satisfied']), test['satisfied']\n",
    "y_train.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 - Na√Øve Bayes Classifier for Categorical Attributes (15 points)\n",
    "\n",
    "Use the categorical attributes **only**, please build a Categorical Na√Øve Bayes classifier that predicts the column `satisfied`. <br >\n",
    "Report the **testing result** using `classification_report`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      quarter  department  day  team\n",
       "961         3           0    3     0\n",
       "467         3           0    1     0\n",
       "1048        0           1    2     7\n",
       "1179        1           0    2     2\n",
       "710         1           0    1     7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "961     1\n",
       "467     1\n",
       "1048    1\n",
       "1179    1\n",
       "710     0\n",
       "Name: satisfied, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test ----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     quarter  department  day  team\n",
       "230        1           0    1     2\n",
       "550        0           0    6     9\n",
       "824        2           1    2     5\n",
       "394        3           1    5     9\n",
       "213        1           1    0    10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "230    0\n",
       "550    1\n",
       "824    1\n",
       "394    1\n",
       "213    0\n",
       "Name: satisfied, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember to do this task with your processed data from Exercise 2.1\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "# Step 1:Keep categorical attributes only\n",
    "X_train = X_train_org.copy() #clone X_train_org\n",
    "X_test  = X_test_org.copy()  #clone X_test_org\n",
    "for col in X_train:\n",
    "   if not col  in categorical_attributes:\n",
    "    del X_train[col]\n",
    "for col in X_test:\n",
    "   if not col  in categorical_attributes:\n",
    "    del X_test[col]\n",
    "print(\"--- Train ----\")\n",
    "display(X_train.head())\n",
    "display(y_train.head())\n",
    "print(\"--- Test ----\")\n",
    "display(X_test.head())\n",
    "display(y_test.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- classification Train Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.20      0.29       254\n",
      "           1       0.76      0.94      0.84       703\n",
      "\n",
      "    accuracy                           0.74       957\n",
      "   macro avg       0.66      0.57      0.57       957\n",
      "weighted avg       0.71      0.74      0.70       957\n",
      "\n",
      "-- classification Test Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.28      0.39        68\n",
      "           1       0.77      0.94      0.85       172\n",
      "\n",
      "    accuracy                           0.75       240\n",
      "   macro avg       0.71      0.61      0.62       240\n",
      "weighted avg       0.74      0.75      0.72       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use CategoricalNB() for performing Categorical Naive-Bayes on numerical data\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "CB = CategoricalNB()\n",
    "CB.fit(X_train, np.asarray(y_train))\n",
    "\n",
    "print(\"-- classification Train Report --\")\n",
    "print(classification_report(y_train, CB.predict(X_train)))\n",
    "print(\"-- classification Test Report --\")\n",
    "print(classification_report(y_test, CB.predict(X_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3 - Na√Øve Bayes Classifier for Numerical Attributes (15 points)\n",
    "\n",
    "Use the numerical attributes **only**, please build a Gaussian Na√Øve Bayes classifier that predicts the column `satisfied`. <br >\n",
    "Report the **testing result** using `classification_report`.\n",
    "\n",
    "**Remember to scale your data. The scaling method is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train ----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>26.66</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>22.94</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>6960</td>\n",
       "      <td>55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>30.1</td>\n",
       "      <td>735.0</td>\n",
       "      <td>6960</td>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>30.1</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>6960</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        smv     wip over_time incentive idle_time idle_men no_of_style_change  \\\n",
       "961   26.66  1164.0      6600        23       0.0        0                  2   \n",
       "467   22.94  1871.0      6960        55       0.0        0                  0   \n",
       "1048    4.6       0       960         0       0.0        0                  0   \n",
       "1179   30.1   735.0      6960        63       0.0        0                  1   \n",
       "710    30.1  1061.0      6960        30       0.0        0                  1   \n",
       "\n",
       "     no_of_workers  \n",
       "961           55.0  \n",
       "467           58.0  \n",
       "1048           8.0  \n",
       "1179          58.0  \n",
       "710           58.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "961     1\n",
       "467     1\n",
       "1048    1\n",
       "1179    1\n",
       "710     0\n",
       "Name: satisfied, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test ----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>42.27</td>\n",
       "      <td>465.0</td>\n",
       "      <td>9900</td>\n",
       "      <td>54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>22.52</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>6720</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3.94</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>4.15</td>\n",
       "      <td>0</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       smv     wip over_time incentive idle_time idle_men no_of_style_change  \\\n",
       "230  42.27   465.0      9900        54       0.0        0                  0   \n",
       "550  22.52  1282.0      6720        75       0.0        0                  0   \n",
       "824    2.9       0      1440         0       0.0        0                  0   \n",
       "394   3.94       0      1800         0       0.0        0                  0   \n",
       "213   4.15       0      1440         0       0.0        0                  0   \n",
       "\n",
       "    no_of_workers  \n",
       "230          55.0  \n",
       "550          56.0  \n",
       "824          12.0  \n",
       "394          10.0  \n",
       "213           8.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "230    0\n",
       "550    1\n",
       "824    1\n",
       "394    1\n",
       "213    0\n",
       "Name: satisfied, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- classification Train Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.04      0.08       254\n",
      "           1       0.74      0.99      0.85       703\n",
      "\n",
      "    accuracy                           0.74       957\n",
      "   macro avg       0.74      0.52      0.47       957\n",
      "weighted avg       0.74      0.74      0.65       957\n",
      "\n",
      "-- classification Test Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.08        68\n",
      "           1       0.73      1.00      0.84       172\n",
      "\n",
      "    accuracy                           0.73       240\n",
      "   macro avg       0.86      0.52      0.46       240\n",
      "weighted avg       0.80      0.73      0.63       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remember to do this task with your processed data from Exercise 2.1\n",
    "# Use GaussianNB() for performing Gaussian Naive-Bayes on numerical data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "NB = GaussianNB()\n",
    "# Step 1:Keep numerical attributes only and delete categorical_attributes\n",
    "X_train = X_train_org.copy() #clone X_train_org\n",
    "X_test  = X_test_org.copy()  #clone X_test_org\n",
    "#delete all categorical_attributes\n",
    "for col in X_train:\n",
    "   if col in categorical_attributes:\n",
    "    del X_train[col]\n",
    "for col in X_test:\n",
    "   if col in categorical_attributes:\n",
    "    del X_test[col]\n",
    "print(\"--- Train ----\")\n",
    "display(X_train.head())\n",
    "display(y_train.head())\n",
    "print(\"--- Test ----\")\n",
    "display(X_test.head())\n",
    "display(y_test.head())\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_numerical_attributes_scaler = scaler.transform(X_train).copy() # save it to later use \n",
    "X_test_numerical_attributes_scaler = scaler.transform(X_test).copy()   # save it to later use\n",
    "NB.fit(scaler.transform(X_train), np.asarray(y_train))\n",
    "print(\"-- classification Train Report --\")\n",
    "print(classification_report(y_train, NB.predict(scaler.transform(X_train))))\n",
    "print(\"-- classification Test Report --\")\n",
    "print(classification_report(y_test, NB.predict(scaler.transform(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercies 3 - SVM Classifier (40 points in total)\n",
    "\n",
    "### Exercise 3.1 - Additional Data Preprocessing (10 points)\n",
    "\n",
    "To build a SVM Classifier, we need a different encoding for our categorical variables.\n",
    "\n",
    " - For each of the **categorical attribtues**, encode them with **one-hot encoding**.\n",
    "     - You can find information about this encoding in the discussion materials.\n",
    "\n",
    "\n",
    " - Split the data into training and testing set with the ratio of 80:20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.71156403,  0.70466889,  0.71038598,  0.0850198 , -0.06338855,\n",
       "        -0.1147066 , -0.35080434,  1.0421417 ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.71662743,  0.87812142,  0.66567643,  0.59743145, -0.11125405,\n",
       "        -0.10599979, -0.35486811,  1.01284675,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# Step 1:Keep numerical attributes only and delete categorical_attributes\n",
    "X_train = X_train_org.copy() #clone X_train_org\n",
    "X_test  = X_test_org.copy()  #clone X_test_org\n",
    "\n",
    "# Define which columns should be encoded vs scaled\n",
    "columns_to_scale = ['smv','wip','over_time','incentive','idle_time','idle_men','no_of_style_change','no_of_workers']\n",
    "columns_to_encode  = ['quarter','department','day','team']\n",
    "\n",
    "# Instantiate encoder/scaler\n",
    "scaler = StandardScaler()\n",
    "ohe    = OneHotEncoder(sparse=False)\n",
    "\n",
    "# ---- prepare X_train ----\n",
    "# Scale and Encode Separate Columns\n",
    "scaled_columns  = scaler.fit_transform(X_train[columns_to_scale]) \n",
    "encoded_columns =    ohe.fit_transform(X_train[columns_to_encode])\n",
    "\n",
    "# Concatenate (Column-Bind) Processed Columns Back Together\n",
    "X_train_processed_data = np.concatenate([scaled_columns, encoded_columns], axis=1)\n",
    "\n",
    "display(X_train_processed_data[1:2])\n",
    "\n",
    "# ---- prepare X_test ----\n",
    "# Scale and Encode Separate Columns\n",
    "scaled_columns  = scaler.fit_transform(X_test[columns_to_scale]) \n",
    "encoded_columns =    ohe.fit_transform(X_test[columns_to_encode])\n",
    "\n",
    "# Concatenate (Column-Bind) Processed Columns Back Together\n",
    "X_test_processed_data = np.concatenate([scaled_columns, encoded_columns], axis=1)\n",
    "\n",
    "display(X_test_processed_data[1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2 - SVM with Different Kernels (20 points)\n",
    "\n",
    "Using all the attributes we have, please build a SVM that predicts the column `satisfied`. <br >\n",
    "Specifically, please \n",
    " - Build one SVM with **linear kernel**.\n",
    " - Build another SVM but with **rbf kernel**.\n",
    " - Report the **testing results** of **both models** using `classification report`.\n",
    "\n",
    "The kernel is the only setting requirement. <br >\n",
    "Other hyperparameter tuning is not required. But make sure they are the same in these two SVMs if you'd like to tune the model. In other words, the only difference between the two SVMs should be the kernel setting.\n",
    "\n",
    "**Remember to scale your data. The scaling method is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- kernel='linear': classification Train Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.04      0.08       254\n",
      "           1       0.74      1.00      0.85       703\n",
      "\n",
      "    accuracy                           0.74       957\n",
      "   macro avg       0.79      0.52      0.47       957\n",
      "weighted avg       0.77      0.74      0.65       957\n",
      "\n",
      "-- kernel='linear': classification Test Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.08        68\n",
      "           1       0.73      1.00      0.84       172\n",
      "\n",
      "    accuracy                           0.73       240\n",
      "   macro avg       0.86      0.52      0.46       240\n",
      "weighted avg       0.80      0.73      0.63       240\n",
      "\n",
      "-- kernel='RBF': classification Train Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.09      0.16       254\n",
      "           1       0.75      0.99      0.86       703\n",
      "\n",
      "    accuracy                           0.75       957\n",
      "   macro avg       0.80      0.54      0.51       957\n",
      "weighted avg       0.78      0.75      0.67       957\n",
      "\n",
      "-- kernel='RBF': classification Test Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.04      0.08        68\n",
      "           1       0.72      0.99      0.84       172\n",
      "\n",
      "    accuracy                           0.73       240\n",
      "   macro avg       0.74      0.52      0.46       240\n",
      "weighted avg       0.73      0.72      0.62       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remember to do this task with your processed data from Exercise 3.1\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "#Create a svm Classifier kernel='linear'\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train_processed_data, y_train)\n",
    "print(\"-- kernel='linear': classification Train Report --\")\n",
    "print(classification_report(y_train, clf.predict(X_train_processed_data)))\n",
    "print(\"-- kernel='linear': classification Test Report --\")\n",
    "print(classification_report(y_test, clf.predict(X_test_processed_data)))\n",
    "\n",
    "# Create a SVC classifier using an RBF kernel\n",
    "svm = svm.SVC(kernel='rbf', random_state=0, gamma=.01, C=10)\n",
    "# Train the classifier\n",
    "svm.fit(X_train_processed_data, y_train)\n",
    "\n",
    "print(\"-- kernel='RBF': classification Train Report --\")\n",
    "print(classification_report(y_train, svm.predict(X_train_processed_data)))\n",
    "print(\"-- kernel='RBF': classification Test Report --\")\n",
    "print(classification_report(y_test, svm.predict(X_test_processed_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3 - SVM with Over-sampling (10 points)\n",
    " - For the column `satisfied` in our **training set**, please **print out** the frequency of each class. \n",
    " - Oversample the **training data**. \n",
    " - For the column `satisfied` in the oversampled data, **print out** the frequency of each class  again.\n",
    " - Re-build the 2 SVMs with the same setting you have in Exercise 3.2, but **use oversampled training data** instead.\n",
    "     - Do not forget to scale the data first. As always, the scaling method is up to you.\n",
    " - Report the **testing result** with `classification_report`.\n",
    "\n",
    "You can use ANY methods listed on [here](https://imbalanced-learn.org/stable/references/over_sampling.html#) such as RandomOverSampler or SMOTE. <br > \n",
    "You are definitely welcomed to build your own oversampler. <br >\n",
    "\n",
    "Note that you do not have to over-sample your testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    703\n",
      "0    254\n",
      "Name: satisfied, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remember to do this task with your processed data from Exercise 3.1\n",
    "#For the column satisfied in our training set, please print out the frequency of each class.\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    703\n",
      "1    703\n",
      "Name: satisfied, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Oversample the training data.\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=21)\n",
    "X_os_train, y_os = ros.fit_resample(X_train_processed_data, y_train)\n",
    "print(y_os.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.05128214  0.27511996  0.60125373 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.71156403  0.70466889  0.71038598 ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.96328278 -0.43208649 -1.10848494 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-1.02355535 -0.43208649 -1.03573011 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.1185303  -0.43208649 -0.96297527 ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.1185303  -0.43208649 -0.96297527 ...  0.          0.\n",
      "   0.        ]] (1406, 33)\n",
      "--- Train ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.05128214,  0.27511996,  0.60125373, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.71156403,  0.70466889,  0.71038598, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.96328278, -0.43208649, -1.10848494, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.02355535, -0.43208649, -1.03573011, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.1185303 , -0.43208649, -0.96297527, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.1185303 , -0.43208649, -0.96297527, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       0\n",
       "       ..\n",
       "1401    0\n",
       "1402    0\n",
       "1403    0\n",
       "1404    0\n",
       "1405    0\n",
       "Name: satisfied, Length: 1406, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.53097099, -0.16122357,  1.56702345, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.71662743,  0.87812142,  0.66567643, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.08577362, -0.75277243, -0.83089976, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.97737233, -0.75277243,  0.29153238, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.02713281,  0.84377342,  0.68268297, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.08577362, -0.75277243, -0.558795  , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "230    0\n",
       "550    1\n",
       "824    1\n",
       "394    1\n",
       "213    0\n",
       "      ..\n",
       "724    1\n",
       "324    0\n",
       "392    0\n",
       "68     1\n",
       "366    0\n",
       "Name: satisfied, Length: 240, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember to continue the task with your processed data from Exercise 1\n",
    "#Split the data into training and testing set with the ratio of 80:20 = already done \n",
    "print(X_os_train, X_os_train.shape)\n",
    "    \n",
    "print(\"--- Train ----\")\n",
    "display(X_os_train)\n",
    "display(y_os)\n",
    "print(\"--- Test ----\")\n",
    "display(X_test_processed_data)\n",
    "display(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- kernel='linear': classification Train Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.78      0.73       703\n",
      "           1       0.74      0.63      0.68       703\n",
      "\n",
      "    accuracy                           0.71      1406\n",
      "   macro avg       0.71      0.71      0.71      1406\n",
      "weighted avg       0.71      0.71      0.71      1406\n",
      "\n",
      "-- kernel='linear': classification Test Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.84      0.62        68\n",
      "           1       0.91      0.65      0.76       172\n",
      "\n",
      "    accuracy                           0.70       240\n",
      "   macro avg       0.70      0.74      0.69       240\n",
      "weighted avg       0.79      0.70      0.72       240\n",
      "\n",
      "-- kernel='RBF': classification Train Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77       703\n",
      "           1       0.82      0.62      0.71       703\n",
      "\n",
      "    accuracy                           0.74      1406\n",
      "   macro avg       0.76      0.74      0.74      1406\n",
      "weighted avg       0.76      0.74      0.74      1406\n",
      "\n",
      "-- kernel='RBF': classification Test Report --\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.79      0.58        68\n",
      "           1       0.89      0.63      0.74       172\n",
      "\n",
      "    accuracy                           0.68       240\n",
      "   macro avg       0.67      0.71      0.66       240\n",
      "weighted avg       0.77      0.68      0.70       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a svm Classifier kernel='linear'\n",
    "#clf = svm.SVC(kernel='linear') # Linear Kernel already done\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_os_train, y_os)\n",
    "print(\"-- kernel='linear': classification Train Report --\")\n",
    "print(classification_report(y_os, clf.predict(X_os_train)))\n",
    "print(\"-- kernel='linear': classification Test Report --\")\n",
    "print(classification_report(y_test, clf.predict(X_test_processed_data)))\n",
    "\n",
    "#Create a SVC classifier using an RBF kernel\n",
    "#svm = svm.SVC(kernel='rbf', random_state=0, gamma=.01, C=10)  already done\n",
    "# Train the classifier\n",
    "svm.fit(X_os_train, y_os)\n",
    "\n",
    "print(\"-- kernel='RBF': classification Train Report --\")\n",
    "print(classification_report(y_os, svm.predict(X_os_train)))\n",
    "print(\"-- kernel='RBF': classification Test Report --\")\n",
    "print(classification_report(y_test, svm.predict(X_test_processed_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
